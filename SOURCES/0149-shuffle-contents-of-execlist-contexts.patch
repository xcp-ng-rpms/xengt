From a24ba15c36ec78e55c6f093d9373032093908819 Mon Sep 17 00:00:00 2001
From: Zhiyuan Lv <zhiyuan.lv@intel.com>
Date: Mon, 27 Jul 2015 06:35:46 +0800
Subject: [PATCH 149/403] shuffle contents of execlist contexts

No functional changes

Signed-off-by: Zhiyuan Lv <zhiyuan.lv@intel.com>
---
 drivers/gpu/drm/i915/vgt/execlists.h |   33 ++++++++++++++++++++++++++++++++
 drivers/gpu/drm/i915/vgt/vgt.h       |   35 +---------------------------------
 2 files changed, 34 insertions(+), 34 deletions(-)

diff --git a/drivers/gpu/drm/i915/vgt/execlists.h b/drivers/gpu/drm/i915/vgt/execlists.h
index dc0c809..88d8ed40 100644
--- a/drivers/gpu/drm/i915/vgt/execlists.h
+++ b/drivers/gpu/drm/i915/vgt/execlists.h
@@ -171,6 +171,39 @@ struct ctx_st_ptr_format {
 	};
 };
 
+/* shadow context */
+
+struct shadow_ctx_page {
+	guest_page_t guest_page;
+	shadow_page_t shadow_page;
+	struct vgt_device *vgt;
+};
+
+struct execlist_context {
+	struct ctx_desc_format guest_context;
+	uint32_t shadow_lrca;
+	uint32_t error_reported;
+	enum vgt_ring_id ring_id;
+	/* below are some per-ringbuffer data. Since with execlist,
+	 * each context has its own ring buffer, here we store the
+	 * data and store them into vgt->rb[ring_id] before a
+	 * context is submitted. We will have better handling later.
+	 */
+	vgt_reg_t last_guest_head;
+	vgt_reg_t last_scan_head;
+	uint64_t request_id;
+	//uint64_t cmd_nr;
+	//vgt_reg_t uhptr;
+	//uint64_t uhptr_id;
+
+	struct vgt_mm *ppgtt_mm;
+	struct shadow_ctx_page ctx_pages[MAX_EXECLIST_CTX_PAGES];
+	/* used for lazy context shadowing optimization */
+	gtt_entry_t shadow_entry_backup[MAX_EXECLIST_CTX_PAGES];
+
+	struct hlist_node node;
+};
+
 /* read execlist status or ctx status which are 64-bit MMIO
  * status can be different types but all with ldw/udw defined.
  */
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index 4c202ee..ec11447 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -49,13 +49,13 @@ struct vgt_device;
 #include "edid.h"
 #include "cmd_parser.h"
 #include "hypercall.h"
-#include "execlists.h"
 #include "gtt.h"
 #include "interrupt.h"
 #include "mmio.h"
 #include "perf.h"
 #include "render.h"
 #include "sched.h"
+#include "execlists.h"
 
 extern struct vgt_device *vgt_dom0;
 extern struct pgt_device *perf_pgt;
@@ -197,39 +197,6 @@ struct vgt_mm;
 
 struct vgt_device;
 
-/* shadow context */
-
-struct shadow_ctx_page {
-	guest_page_t guest_page;
-	shadow_page_t shadow_page;
-	struct vgt_device *vgt;
-};
-
-struct execlist_context {
-	struct ctx_desc_format guest_context;
-	uint32_t shadow_lrca;
-	uint32_t error_reported;
-	enum vgt_ring_id ring_id;
-	/* below are some per-ringbuffer data. Since with execlist,
-	 * each context has its own ring buffer, here we store the
-	 * data and store them into vgt->rb[ring_id] before a
-	 * context is submitted. We will have better handling later.
-	 */
-	vgt_reg_t last_guest_head;
-	vgt_reg_t last_scan_head;
-	uint64_t request_id;
-	//uint64_t cmd_nr;
-	//vgt_reg_t uhptr;
-	//uint64_t uhptr_id;
-
-	struct vgt_mm *ppgtt_mm;
-	struct shadow_ctx_page ctx_pages[MAX_EXECLIST_CTX_PAGES];
-	/* used for lazy context shadowing optimization */
-	gtt_entry_t shadow_entry_backup[MAX_EXECLIST_CTX_PAGES];
-
-	struct hlist_node node;
-};
-
 extern bool vgt_render_init(struct pgt_device *pdev);
 extern bool idle_rendering_engines(struct pgt_device *pdev, int *id);
 extern bool idle_render_engine(struct pgt_device *pdev, int id);
-- 
1.7.10.4

