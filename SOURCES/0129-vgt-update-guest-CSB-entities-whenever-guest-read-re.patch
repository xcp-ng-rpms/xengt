From 645cda9b5641d1b32804c77c5bbbf56a1a0a81fe Mon Sep 17 00:00:00 2001
From: "Zheng, Xiao" <xiao.zheng@intel.com>
Date: Mon, 20 Jul 2015 18:58:43 +0800
Subject: [PATCH 129/403] vgt: update guest CSB entities whenever guest read
 reg23a0

The fix is to enhance stability test [MTBF]:
update HW CSB status to guest if we are render owner
this is to make sure that guest always can get latest HW status,
even if we delay or missed to send ctx switch events to guest.

Signed-off-by: Zheng, Xiao <xiao.zheng@intel.com>
---
 drivers/gpu/drm/i915/intel_lrc.c     |    2 +-
 drivers/gpu/drm/i915/vgt/execlists.c |    8 ++++
 drivers/gpu/drm/i915/vgt/handlers.c  |   67 +++++++++++++++++++++++++++++++---
 drivers/gpu/drm/i915/vgt/interrupt.c |   15 +++++---
 drivers/gpu/drm/i915/vgt/vgt.c       |    1 -
 drivers/gpu/drm/i915/vgt/vgt.h       |    4 +-
 6 files changed, 81 insertions(+), 16 deletions(-)

diff --git a/drivers/gpu/drm/i915/intel_lrc.c b/drivers/gpu/drm/i915/intel_lrc.c
index 4214056..7793b42 100644
--- a/drivers/gpu/drm/i915/intel_lrc.c
+++ b/drivers/gpu/drm/i915/intel_lrc.c
@@ -597,7 +597,7 @@ void intel_lrc_irq_handler(struct intel_engine_cs *ring)
 	I915_WRITE(RING_CONTEXT_STATUS_PTR(ring),
 		   _MASKED_FIELD(GEN8_CSB_PTR_MASK << 8,
 				 ((u32)ring->next_context_status_buffer &
-				  GEN8_CSB_PTR_MASK) << 8));
+				  GEN8_CSB_PTR_MASK) << 8) | 0x07000000);
 }
 
 static int execlists_context_queue(struct drm_i915_gem_request *request)
diff --git a/drivers/gpu/drm/i915/vgt/execlists.c b/drivers/gpu/drm/i915/vgt/execlists.c
index 1771325..46ce4a8 100644
--- a/drivers/gpu/drm/i915/vgt/execlists.c
+++ b/drivers/gpu/drm/i915/vgt/execlists.c
@@ -1469,9 +1469,11 @@ bool vgt_idle_execlist(struct pgt_device *pdev, enum vgt_ring_id ring_id)
 	struct execlist_status_format el_status;
 	uint32_t ctx_ptr_reg;
 	struct ctx_st_ptr_format ctx_st_ptr;
+	struct ctx_st_ptr_format guest_ctx_st_ptr;
 	struct context_status_format ctx_status;
 	uint32_t ctx_status_reg = el_ring_mmio(ring_id, _EL_OFFSET_STATUS_BUF);
 	unsigned long last_csb_reg_offset;
+	struct vgt_device* vgt = current_render_owner(pdev);
 
 	el_ring_base = vgt_ring_id_to_EL_base(ring_id);
 	el_status_reg = el_ring_base + _EL_OFFSET_STATUS;
@@ -1496,6 +1498,12 @@ bool vgt_idle_execlist(struct pgt_device *pdev, enum vgt_ring_id ring_id)
 	if (!ctx_status.active_to_idle)
 		return false;
 
+	/* check Guest ctx status pointers, make sure guest already received last irq update */
+	guest_ctx_st_ptr.dw = __vreg(vgt, ctx_ptr_reg);
+	if (guest_ctx_st_ptr.status_buf_write_ptr != vgt->rb[ring_id].csb_write_ptr) {
+		return false;
+	}
+
 	return true;
 }
 
diff --git a/drivers/gpu/drm/i915/vgt/handlers.c b/drivers/gpu/drm/i915/vgt/handlers.c
index 9f3bc5c..62e0d89 100644
--- a/drivers/gpu/drm/i915/vgt/handlers.c
+++ b/drivers/gpu/drm/i915/vgt/handlers.c
@@ -563,29 +563,34 @@ static int mmio_to_ring_id(unsigned int reg)
 	case _REG_RCS_GFX_MODE_IVB:
 	case _REG_RCS_EXECLIST_SUBMITPORT:
 	case _REG_RCS_EXECLIST_STATUS:
+	case _REG_RCS_CTX_STATUS_PTR:
 		ring_id = RING_BUFFER_RCS;
 		break;
 	case _REG_BCS_PP_DIR_BASE:
 	case _REG_BCS_BLT_MODE_IVB:
 	case _REG_BCS_EXECLIST_SUBMITPORT:
 	case _REG_BCS_EXECLIST_STATUS:
+	case _REG_BCS_CTX_STATUS_PTR:
 		ring_id = RING_BUFFER_BCS;
 		break;
 	case _REG_VCS_PP_DIR_BASE:
 	case _REG_VCS_MFX_MODE_IVB:
 	case _REG_VCS_EXECLIST_SUBMITPORT:
 	case _REG_VCS_EXECLIST_STATUS:
+	case _REG_VCS_CTX_STATUS_PTR:
 		ring_id = RING_BUFFER_VCS;
 		break;
 	case _REG_VECS_PP_DIR_BASE:
 	case _REG_VEBOX_MODE:
 	case _REG_VECS_EXECLIST_SUBMITPORT:
 	case _REG_VECS_EXECLIST_STATUS:
+	case _REG_VECS_CTX_STATUS_PTR:
 		ring_id = RING_BUFFER_VECS;
 		break;
 	case _REG_VCS2_MFX_MODE_BDW:
 	case _REG_VCS2_EXECLIST_SUBMITPORT:
 	case _REG_VCS2_EXECLIST_STATUS:
+	case _REG_VCS2_CTX_STATUS_PTR:
 		ring_id = RING_BUFFER_VCS2;
 		break;
 	default:
@@ -2358,6 +2363,53 @@ static bool vgt_write_submitport(struct vgt_device *vgt, unsigned int offset,
 	return rc;
 }
 
+
+static bool vgt_read_ctx_status_ptr(struct vgt_device *vgt, unsigned int offset,
+	void *p_data, unsigned int bytes)
+{
+	int ring_id = mmio_to_ring_id(offset);
+
+	if (vgt == current_render_owner(vgt->pdev)) {
+		/* update HW CSB status to guest if we are render owner
+		 * this is to make sure that guest always can get latest HW status,
+		 * even if we delay/did not send ctx switch events to guest.
+		 */
+		vgt_emulate_context_switch_event(vgt->pdev, ring_id);
+	}
+
+	return default_mmio_read(vgt, offset, p_data, bytes);
+}
+
+static bool vgt_write_ctx_status_ptr(struct vgt_device *vgt, unsigned int offset,
+	void *p_data, unsigned int bytes)
+{
+#if 0
+	int ring_id = mmio_to_ring_id(offset);
+	uint32_t ctx_ptr_reg;
+	struct ctx_st_ptr_format ctx_ptr_val;
+	struct ctx_st_ptr_format* guest_ctx_st = (struct ctx_st_ptr_format*)p_data;
+
+	ASSERT(bytes == 4);
+
+	ctx_ptr_reg = el_ring_mmio(ring_id, _EL_OFFSET_STATUS_PTR);
+	ctx_ptr_val.dw = __vreg(vgt, ctx_ptr_reg);
+
+	/* Guest modify write_ptr as long as mask bits not zero */
+	if ((guest_ctx_st->mask & _CTXBUF_WRITE_PTR_MASK) == _CTXBUF_WRITE_PTR_MASK) {
+		ctx_ptr_val.status_buf_write_ptr = guest_ctx_st->status_buf_write_ptr;
+	}
+
+	/* Guest modify read_ptr as long as not zero */
+	if ((guest_ctx_st->mask & _CTXBUF_READ_PTR_MASK) == _CTXBUF_READ_PTR_MASK) {
+		ctx_ptr_val.status_buf_read_ptr = guest_ctx_st->status_buf_read_ptr;
+	}
+
+	/* update into vreg */
+	guest_ctx_st->dw = ctx_ptr_val.dw;
+#endif
+	return default_mmio_write(vgt, offset, p_data, bytes);
+}
+
 /*
  * Track policies of all captured registers
  *
@@ -2683,11 +2735,16 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_BCS_CTX_STATUS_BUF, 48, F_VIRT, 0, D_BDW_PLUS, NULL,
 					vgt_not_allowed_mmio_write},
 
-{_REG_RCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, NULL, NULL},
-{_REG_VCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, NULL, NULL},
-{_REG_VECS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, NULL, NULL},
-{_REG_VCS2_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, NULL, NULL},
-{_REG_BCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, NULL, NULL},
+{_REG_RCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, vgt_read_ctx_status_ptr,
+	vgt_write_ctx_status_ptr},
+{_REG_VCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, vgt_read_ctx_status_ptr,
+	vgt_write_ctx_status_ptr},
+{_REG_VECS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, vgt_read_ctx_status_ptr,
+	vgt_write_ctx_status_ptr},
+{_REG_VCS2_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, vgt_read_ctx_status_ptr,
+	vgt_write_ctx_status_ptr},
+{_REG_BCS_CTX_STATUS_PTR, 4, F_VIRT | VGT_REG_MODE_CTL, 0, D_BDW_PLUS, vgt_read_ctx_status_ptr,
+	vgt_write_ctx_status_ptr},
 
 	/* -------display regs---------- */
 
diff --git a/drivers/gpu/drm/i915/vgt/interrupt.c b/drivers/gpu/drm/i915/vgt/interrupt.c
index 1294a50..9f0d6ea 100644
--- a/drivers/gpu/drm/i915/vgt/interrupt.c
+++ b/drivers/gpu/drm/i915/vgt/interrupt.c
@@ -1129,6 +1129,15 @@ static void vgt_handle_ctx_switch_virt(struct vgt_irq_host_state *hstate,
 		csb_has_new_updates = true;
 
 	if (hvm_render_owner || csb_has_new_updates) {
+
+		if (current_render_owner(vgt->pdev) != vgt) {
+			/* In any case, we should not go here! */
+			vgt_err("ERROR VM inject irq without ownership"
+			" VM%d owner=%d, csb=%04x, s=%x\n",
+			vgt->vm_id, current_render_owner(vgt->pdev)->vm_id,
+			ctx_ptr_val.dw, s_write_ptr);
+		}
+
 		ctx_ptr_val.status_buf_write_ptr = s_write_ptr;
 		__vreg(vgt, ctx_ptr_reg) = ctx_ptr_val.dw;
 		vgt_handle_default_event_virt(hstate, event, vgt);
@@ -1320,15 +1329,9 @@ static void vgt_handle_port_hotplug_phys(struct vgt_irq_host_state *hstate,
 static void vgt_handle_ctx_switch_phys(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event)
 {
-	uint32_t ctx_ptr_reg;
-	struct ctx_st_ptr_format ctx_st_ptr;
 	struct pgt_device *pdev = hstate->pdev;
 	enum vgt_ring_id ring_id = event_to_ring_id(event);
 
-	ctx_ptr_reg = el_ring_mmio(ring_id, _EL_OFFSET_STATUS_PTR);
-	ctx_st_ptr.dw = VGT_MMIO_READ(pdev, ctx_ptr_reg);
-	el_write_ptr(pdev, ring_id) = ctx_st_ptr.status_buf_write_ptr;
-
 	vgt_raise_request(pdev, VGT_REQUEST_CTX_EMULATION_RCS + ring_id);
 
 	vgt_handle_default_event_phys(hstate, event);
diff --git a/drivers/gpu/drm/i915/vgt/vgt.c b/drivers/gpu/drm/i915/vgt/vgt.c
index 265c1fe..1da105d 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.c
+++ b/drivers/gpu/drm/i915/vgt/vgt.c
@@ -507,7 +507,6 @@ bool initial_phys_states(struct pgt_device *pdev)
 
 	for (i = 0; i < MAX_ENGINES; ++ i) {
 		pdev->el_read_ptr[i] = DEFAULT_INV_SR_PTR;
-		pdev->el_cache_write_ptr[i] = DEFAULT_INV_SR_PTR;
 	}
 
 	return true;
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index 7c08ee1..ae5183d 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -1318,7 +1318,6 @@ struct pgt_device {
 
 	bool ctx_switch_pending;
 
-	uint32_t el_cache_write_ptr[MAX_ENGINES];
 	uint32_t el_read_ptr[MAX_ENGINES];
 };
 
@@ -1401,7 +1400,7 @@ extern void do_vgt_fast_display_switch(struct pgt_device *pdev);
 	(pdev->vgt_aux_table[reg_aux_index(pdev, reg)].addr_fix.size)
 
 #define el_read_ptr(pdev, ring_id) ((pdev)->el_read_ptr[ring_id])
-#define el_write_ptr(pdev, ring_id) ((pdev)->el_cache_write_ptr[ring_id])
+#define el_write_ptr(pdev, ring_id) ((VGT_MMIO_READ((pdev), el_ring_mmio((ring_id), _EL_OFFSET_STATUS_PTR))) & 0x7 )
 
 #define ASSERT(x)							\
 	do {								\
@@ -2977,7 +2976,6 @@ static inline void reset_el_structure(struct pgt_device *pdev,
 				enum vgt_ring_id ring_id)
 {
 	el_read_ptr(pdev, ring_id) = DEFAULT_INV_SR_PTR;
-	el_write_ptr(pdev, ring_id) = DEFAULT_INV_SR_PTR;
 	vgt_clear_submitted_el_record(pdev, ring_id);
 	/* reset read ptr in MMIO as well */
 	VGT_MMIO_WRITE(pdev, el_ring_mmio(ring_id, _EL_OFFSET_STATUS_PTR),
-- 
1.7.10.4

