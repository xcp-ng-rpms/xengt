From 01983f9b7c670b02bc2328d72e9cfacb854339e5 Mon Sep 17 00:00:00 2001
From: Zhiyuan Lv <zhiyuan.lv@intel.com>
Date: Thu, 29 Oct 2015 10:39:37 +0800
Subject: [PATCH 273/403] Cleanup context creation function

Refactor the big loop in shadow context creation to make the code more
readable. There is no functional impact.

Signed-off-by: Zhiyuan Lv <zhiyuan.lv@intel.com>
---
 drivers/gpu/drm/i915/vgt/execlists.c |  257 +++++++++++++++++++++-------------
 1 file changed, 157 insertions(+), 100 deletions(-)

diff --git a/drivers/gpu/drm/i915/vgt/execlists.c b/drivers/gpu/drm/i915/vgt/execlists.c
index 8ab7117..a7ed194 100644
--- a/drivers/gpu/drm/i915/vgt/execlists.c
+++ b/drivers/gpu/drm/i915/vgt/execlists.c
@@ -717,88 +717,163 @@ static struct execlist_context *vgt_allocate_el_context(struct vgt_device *vgt,
 	return el_ctx;
 }
 
-static void vgt_el_create_shadow_context(struct vgt_device *vgt,
-				enum vgt_ring_id ring_id,
-				struct execlist_context *el_ctx)
+static void vgt_free_el_context(struct execlist_context *el_ctx)
+{
+	if (el_ctx == NULL)
+		return;
+
+	hash_del(&el_ctx->node);
+	kfree(el_ctx);
+}
+
+static int vgt_create_shadow_pages(struct vgt_device *vgt, struct execlist_context *el_ctx)
 {
 	struct vgt_gtt_pte_ops *ops = vgt->pdev->gtt.pte_ops;
-	uint32_t gfn;
-	uint32_t shadow_context_gma;
-	uint32_t guest_context_gma;
-	uint32_t sl, gl;
+	uint32_t ring_id = el_ctx->ring_id;
+	uint32_t ctx_pages = EXECLIST_CTX_PAGES(ring_id);
+	unsigned long hpa;
+	uint32_t size;
 	uint32_t rsvd_pages_idx;
-	uint32_t rsvd_aperture_gm;
+	unsigned long g_gma;
+	unsigned long s_gma;
 	int i;
-	int ctx_pages = EXECLIST_CTX_PAGES(ring_id);
 
-	guest_context_gma = el_ctx->guest_context.lrca << GTT_PAGE_SHIFT;
+	size = (EXECLIST_CTX_PAGES(ring_id) << GTT_PAGE_SHIFT);
+	hpa = rsvd_aperture_alloc(vgt->pdev, size);
+	if (hpa == 0) {
+		vgt_err("VM-%d: Failed to allocate gm for shadow context!\n",
+			vgt->vm_id);
+		return -1;
+	}
 
-	shadow_context_gma = aperture_2_gm(vgt->pdev,
-				rsvd_aperture_alloc(vgt->pdev,
-					(EXECLIST_CTX_PAGES(ring_id) << GTT_PAGE_SHIFT)));
+	g_gma = el_ctx->guest_context.lrca << GTT_PAGE_SHIFT;
+	s_gma = aperture_2_gm(vgt->pdev, hpa);
 
-	ASSERT((shadow_context_gma & 0xfff) == 0);
-	el_ctx->shadow_lrca = shadow_context_gma >> GTT_PAGE_SHIFT;
+	el_ctx->shadow_lrca = s_gma >> GTT_PAGE_SHIFT;
+
+	rsvd_pages_idx = aperture_page_idx(vgt->pdev, s_gma);
+
+	for (i = 0; i < ctx_pages; ++ i) {
+		shadow_page_t *p_shadow;
+		guest_page_t *p_guest;
+		p_shadow = &el_ctx->ctx_pages[i].shadow_page;
+		p_guest = &el_ctx->ctx_pages[i].guest_page;
+		{
+			p_shadow->vaddr = v_aperture(vgt->pdev, s_gma);
+			p_shadow->page = aperture_page(vgt->pdev, rsvd_pages_idx);
+			memcpy(p_shadow->vaddr, p_guest->vaddr, SIZE_PAGE);
+		}
 
-	rsvd_aperture_gm = aperture_2_gm(vgt->pdev, vgt->pdev->rsvd_aperture_base);
-	rsvd_pages_idx = el_ctx->shadow_lrca - (rsvd_aperture_gm >> GTT_PAGE_SHIFT);
+		g_gma += PAGE_SIZE;
+		s_gma += PAGE_SIZE;
+		rsvd_pages_idx ++;
+	}
 
-	vgt_dbg(VGT_DBG_EXECLIST, "Allocating aperture for shadow context "
-			"with idx: 0x%x and addr: 0x%x\n",
-			rsvd_pages_idx, shadow_context_gma);
+	return 0;
+}
 
-	/* per page copy from guest context to shadow context since its virtual
-	 * address may not be sequential.
-	 */
-	for (i = 0, sl = shadow_context_gma, gl = guest_context_gma; i < ctx_pages;
-			++ i, ++ rsvd_pages_idx, sl += SIZE_PAGE, gl += SIZE_PAGE) {
+static void vgt_destroy_shadow_pages(struct vgt_device *vgt, struct execlist_context *el_ctx)
+{
+	unsigned long hpa;
+	struct vgt_gtt_pte_ops *ops = vgt->pdev->gtt.pte_ops;
+	uint32_t ring_id = el_ctx->ring_id;
+	uint32_t ctx_pages = EXECLIST_CTX_PAGES(ring_id);
+	int i;
+
+	if (el_ctx->shadow_lrca == 0)
+		return;
+
+	hpa = phys_aperture_base(vgt->pdev) + (el_ctx->shadow_lrca << GTT_PAGE_SHIFT);
+	rsvd_aperture_free(vgt->pdev, hpa, ctx_pages << GTT_PAGE_SHIFT);
+
+	return;
+}
+
+static int vgt_el_create_shadow_context(struct vgt_device *vgt,
+				enum vgt_ring_id ring_id,
+				struct execlist_context *el_ctx)
+{
+	struct vgt_gtt_pte_ops *ops = vgt->pdev->gtt.pte_ops;
+	uint32_t guest_lrca = el_ctx->guest_context.lrca;
+	int ret = 0;
+	int i;
+
+	/* init guest context */
+	for (i = 0; i < EXECLIST_CTX_PAGES(ring_id); ++ i) {
 		gtt_entry_t e;
+		guest_page_t *p_guest;
+		unsigned long gfn;
+		guest_page_handler_t *handler;
+
+		p_guest = &el_ctx->ctx_pages[i].guest_page;
+
 		e.pdev = vgt->pdev;
 		e.type = GTT_TYPE_GGTT_PTE;
-
-		ggtt_get_guest_entry(vgt->gtt.ggtt_mm, &e, gl >> GTT_PAGE_SHIFT);
+		ggtt_get_guest_entry(vgt->gtt.ggtt_mm, &e, guest_lrca + i);
 
 		gfn = ops->get_pfn(&e);
-		vgt_dbg(VGT_DBG_EXECLIST,
-			"pfn for context page %i (gma: 0x%x)is: 0x%x\n", i, gl, gfn);
-		if (i == 1) {
-			vgt_init_guest_page(vgt, &el_ctx->ctx_pages[i].guest_page,
-				gfn, sctx_reg_state_wp_handler, &el_ctx);
-		} else {
-			vgt_init_guest_page(vgt, &el_ctx->ctx_pages[i].guest_page,
-				gfn, sctx_mirror_state_wp_handler, &el_ctx);
-		}
-
-		/* backup the shadow context gtt entry */
-		el_ctx->shadow_entry_backup[i].pdev = vgt->pdev;
-		el_ctx->shadow_entry_backup[i].type = GTT_TYPE_GGTT_PTE;
-		ops->get_entry(NULL, &el_ctx->shadow_entry_backup[i],
-						sl >> GTT_PAGE_SHIFT, false, NULL);
+		handler = ((i == 1) ? sctx_reg_state_wp_handler :
+				    sctx_mirror_state_wp_handler);
 
-		{
-			el_ctx->ctx_pages[i].shadow_page.vaddr =
-				phys_aperture_vbase(vgt->pdev) + sl;
-			el_ctx->ctx_pages[i].shadow_page.page =
-				(*vgt->pdev->rsvd_aperture_pages)[rsvd_pages_idx];
-			ASSERT(el_ctx->ctx_pages[i].shadow_page.vaddr &&
-				el_ctx->ctx_pages[i].guest_page.vaddr);
-
-			vgt_dbg(VGT_DBG_EXECLIST, "memory copy for context page %d: dst addr: 0x%llx; "
-					"src addr: 0x%llx\n",
-				i, (u64)el_ctx->ctx_pages[i].shadow_page.vaddr,
-				(u64)el_ctx->ctx_pages[i].guest_page.vaddr);
-
-			if (shadow_execlist_context == NORMAL_CTX_SHADOW) {
-				memcpy(el_ctx->ctx_pages[i].shadow_page.vaddr,
-				el_ctx->ctx_pages[i].guest_page.vaddr, SIZE_PAGE);
-				vgt_set_wp_guest_ctx(vgt, el_ctx, i);
-			}
+		if (false == vgt_init_guest_page(vgt, p_guest, gfn,
+						 handler, &el_ctx)) {
+			vgt_err("VM-%d: Failed to init guest ctx page!\n", vgt->vm_id);
+			ret = -1;
+			break;
 		}
+
 		el_ctx->ctx_pages[i].vgt = vgt;
+
+		if (shadow_execlist_context == NORMAL_CTX_SHADOW)
+			vgt_set_wp_guest_ctx(vgt, el_ctx, i);
+	}
+
+	if (ret)
+		goto cleanup_guest_pages;
+
+	/* init shadow context */
+	ret = vgt_create_shadow_pages(vgt, el_ctx);
+	if (ret)
+		goto cleanup_guest_pages;
+
+	return ret;
+cleanup_guest_pages:
+	for (i = 0; i < EXECLIST_CTX_PAGES(ring_id); ++ i) {
+		guest_page_t *p_guest;
+		p_guest = &el_ctx->ctx_pages[i].guest_page;
+		if (p_guest->writeprotection)
+			vgt_clear_wp_guest_ctx(vgt, el_ctx, i);
+		vgt_clean_guest_page(vgt, p_guest);
 	}
+
+	return ret;
 }
 
-static bool vgt_el_create_shadow_ppgtt(struct vgt_device *vgt,
+static int vgt_el_destroy_shadow_context(struct vgt_device *vgt,
+					 enum vgt_ring_id ring_id,
+					 struct execlist_context *el_ctx)
+{
+	int i;
+
+	if (!vgt_require_shadow_context(vgt))
+		return 0;
+
+	for (i = 0; i < EXECLIST_CTX_PAGES(ring_id); ++ i) {
+		guest_page_t *p_guest;
+		p_guest = &el_ctx->ctx_pages[i].guest_page;
+
+		if (p_guest->writeprotection)
+			vgt_clear_wp_guest_ctx(vgt, el_ctx, i);
+
+		vgt_clean_guest_page(vgt, p_guest);
+	}
+
+	vgt_destroy_shadow_pages(vgt, el_ctx);
+
+	return 0;
+}
+
+static int vgt_el_create_shadow_ppgtt(struct vgt_device *vgt,
 				enum vgt_ring_id ring_id,
 				struct execlist_context *el_ctx)
 {
@@ -847,7 +922,7 @@ static bool vgt_el_create_shadow_ppgtt(struct vgt_device *vgt,
 			pdp, page_table_level, 0);
 	if (!mm) {
 		vgt_err("fail to create mm object.\n");
-		return false;
+		return -1;
 	}
 
 	vgt_warn("Given PPGTT in EL context for creation is not yet constructed! "
@@ -879,19 +954,22 @@ finish:
 			vgt->vm_id);
 		dump_el_context_information(vgt, el_ctx);
 	}
-	return true;
+	return 0;
 }
 
-static struct execlist_context *vgt_create_execlist_context(struct vgt_device *vgt,
-				struct ctx_desc_format *ctx, enum vgt_ring_id ring_id)
+static struct execlist_context *vgt_create_execlist_context(
+					struct vgt_device *vgt,
+					struct ctx_desc_format *ctx,
+					enum vgt_ring_id ring_id)
 {
 	struct execlist_context *el_ctx;
 
-	vgt_dbg(VGT_DBG_EXECLIST, "creating new execlist context with desc below:\n");
-	if (vgt_debug & VGT_DBG_EXECLIST)
+	if (execlist_context_find(vgt, ctx->lrca) != NULL) {
+		vgt_err("VM-%d: Trying to create a context which already exists!\n",
+			vgt->vm_id);
 		dump_ctx_desc(vgt, ctx);
-
-	ASSERT (execlist_context_find(vgt, ctx->lrca) == NULL);
+		return NULL;
+	}
 
 	if (ring_id == MAX_ENGINES) {
 		ring_id = vgt_get_ringid_from_lrca(vgt, ctx->lrca);
@@ -911,8 +989,14 @@ static struct execlist_context *vgt_create_execlist_context(struct vgt_device *v
 	el_ctx->ring_id = ring_id;
 	INIT_LIST_HEAD(&el_ctx->shadow_priv_bb.pages);
 
-	if (vgt_require_shadow_context(vgt))
-		vgt_el_create_shadow_context(vgt, ring_id, el_ctx);
+	if (vgt_require_shadow_context(vgt)) {
+		int ret;
+		ret = vgt_el_create_shadow_context(vgt, ring_id, el_ctx);
+		if(ret) {
+			vgt_free_el_context(el_ctx);
+			return NULL;
+		}
+	}
 
 	vgt_el_create_shadow_ppgtt(vgt, ring_id, el_ctx);
 	vgt_create_shadow_rb(vgt, el_ctx);
@@ -925,9 +1009,7 @@ static struct execlist_context *vgt_create_execlist_context(struct vgt_device *v
 static void vgt_destroy_execlist_context(struct vgt_device *vgt,
 				struct execlist_context *el_ctx)
 {
-	int ctx_pages;
 	enum vgt_ring_id ring_id;
-	int i;
 
 	if (el_ctx == NULL)
 		return;
@@ -941,37 +1023,12 @@ static void vgt_destroy_execlist_context(struct vgt_device *vgt,
 	trace_ctx_lifecycle(vgt->vm_id, ring_id,
 			el_ctx->guest_context.lrca, "destroy");
 
-	ctx_pages = EXECLIST_CTX_PAGES(ring_id);
-
-	for (i = 0; i < ctx_pages; ++ i) {
-		// remove the write protection;
-		if (shadow_execlist_context == NORMAL_CTX_SHADOW) {
-			hypervisor_unset_wp_pages(vgt,
-				&el_ctx->ctx_pages[i].guest_page);
-		}
-		vgt_clean_guest_page(vgt, &el_ctx->ctx_pages[i].guest_page);
-	}
-
 	/* free the shadow cmd buffers */
 	vgt_destroy_shadow_rb(vgt, el_ctx);
 	vgt_release_shadow_cmdbuf(vgt, &el_ctx->shadow_priv_bb);
 
-	// free the shadow context;
-	if (vgt_require_shadow_context(vgt)) {
-		unsigned long start;
-		unsigned int shadow_lrca = el_ctx->shadow_lrca;
-
-		ASSERT(hvm_render_owner || shadow_lrca);
-		if (!hvm_render_owner) {
-			start = phys_aperture_base(vgt->pdev) +
-					(shadow_lrca << GTT_PAGE_SHIFT);
-			rsvd_aperture_free(vgt->pdev, start,
-					ctx_pages << GTT_PAGE_SHIFT);
-		}
-	}
-
-	hash_del(&el_ctx->node);
-	kfree(el_ctx);
+	vgt_el_destroy_shadow_context(vgt, ring_id, el_ctx);
+	vgt_free_el_context(el_ctx);
 }
 
 /* emulate the EXECLIST related MMIOs when vgt is not render owner,
-- 
1.7.10.4

